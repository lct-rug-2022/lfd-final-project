{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44c20623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Embedding, LSTM, Dropout, Bidirectional, MaxPooling1D, Conv1D\n",
    "from keras.initializers import Constant\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from wordsegment import load,segment\n",
    "import io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2866cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting seeds for reproducibility\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "python_random.seed(1234)\n",
    "\n",
    "load() #for wordsegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26ca9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(corpus_file):\n",
    "    '''Read in data set and returns docs and labels'''\n",
    "    documents = []\n",
    "    labels = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip()\n",
    "            documents.append(tokens.split(\"\\t\")[0])\n",
    "            # binary problem: NOT, OFF\n",
    "            labels.append(tokens.split(\"\\t\")[1])\n",
    "    return documents, labels\n",
    "\n",
    "def read_word_emb(embeddings_file, voc):\n",
    "    '''Read embeddings dictionary file'''\n",
    "    fin = io.open(embeddings_file, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in voc:\n",
    "            data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "    return data\n",
    "\n",
    "def get_emb_matrix(voc, emb):\n",
    "    '''Get embedding matrix given vocab and the embeddings'''\n",
    "    num_tokens = len(voc) + 2\n",
    "    word_index = dict(zip(voc, range(len(voc))))\n",
    "    # Bit hacky, get embedding dimension from the word \"the\"\n",
    "    embedding_dim = len(emb[\"the\"])\n",
    "    # Prepare embedding matrix to the correct size\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = emb.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    # Final matrix with pretrained embeddings that we can feed to embedding layer\n",
    "    return embedding_matrix\n",
    "\n",
    "def test_set_predict(model, X_test, Y_test, ident):\n",
    "    '''Do predictions and measure accuracy on our own test set (that we split off train)'''\n",
    "    # Get predictions using the trained model\n",
    "    Y_pred = model.predict(X_test)\n",
    "    # Finally, convert to labels to get scores with sklearn\n",
    "    Y_pred=(Y_pred.flatten()>0.5)*1\n",
    "    # If you have gold data, you can calculate accuracy\n",
    "    Y_test = Y_test.flatten()\n",
    "    print('Accuracy on own {1} set: {0}'.format(round(accuracy_score(Y_test, Y_pred), 3), ident))\n",
    "    return Y_pred\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    '''for getting f1 scores during training'''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    '''learning rate scheduler'''\n",
    "    if epoch < 7:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "def train_model(model, X_train, Y_train, X_dev, Y_dev, batch_size, epochs):\n",
    "    '''Train the model here'''\n",
    "    verbose = 1\n",
    "    batch_size = batch_size\n",
    "    epochs = epochs\n",
    "    # Early stopping\n",
    "    callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    #Learning rate scheduler using function\n",
    "    callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    #Assigning class weights for imbalanced classification\n",
    "    class_weight = {0: 1.,\n",
    "                1: 2.}\n",
    "    # Finally fit the model to our data\n",
    "    model.fit(X_train, Y_train, verbose=verbose, epochs=epochs, callbacks=[callback1,callback2], batch_size=batch_size, validation_data=(X_dev, Y_dev),\n",
    "             class_weight=class_weight)\n",
    "    return model\n",
    "\n",
    "## Best model architecture used after experimenting\n",
    "def create_model(Y_train, emb_matrix, lr):\n",
    "    '''Create the Keras model to use'''\n",
    "    \n",
    "    loss_function = 'binary_crossentropy'\n",
    "    optim = Adam(learning_rate=lr)\n",
    "    \n",
    "    # Take embedding dim and size from emb_matrix\n",
    "    embedding_dim = len(emb_matrix[0])\n",
    "    num_tokens = len(emb_matrix)\n",
    "    \n",
    "    # Now build the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
    "    model.add(LSTM(embedding_dim, dropout=0.2))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    # Compile model using our settings, check for accuracy\n",
    "    model.compile(loss=loss_function, optimizer=optim, metrics=[get_f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e06951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "X_train_org, Y_train = read_corpus(\"datasets/train.tsv\")\n",
    "X_dev_org, Y_dev = read_corpus(\"datasets/val.tsv\")\n",
    "\n",
    "#changing labels to binary\n",
    "encoder = LabelBinarizer()\n",
    "Y_train_bin = encoder.fit_transform(Y_train)  # Use encoder.classes_ to find mapping back\n",
    "Y_dev_bin = encoder.fit_transform(Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29a914",
   "metadata": {},
   "source": [
    "## No preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aad775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text_in):\n",
    "    '''Read in text and preprocesses it and returns'''\n",
    "    return text_in\n",
    "\n",
    "X_train=[preprocess_input(x) for x in X_train_org]\n",
    "X_dev=[preprocess_input(x) for x in X_dev_org]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b783490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 15:43:11.872255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 15:53:44.832583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 15:53:45.541298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 15:53:47.562830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 0s - loss: 0.9213 - get_f1: 0.3688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 15:53:59.721454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 15:53:59.762907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 16s 31ms/step - loss: 0.9213 - get_f1: 0.3688 - val_loss: 0.6960 - val_get_f1: 0.3489 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.9197 - get_f1: 0.3784 - val_loss: 0.6986 - val_get_f1: 0.3937 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "383/383 [==============================] - 11s 29ms/step - loss: 0.9177 - get_f1: 0.4044 - val_loss: 0.6958 - val_get_f1: 0.3957 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "383/383 [==============================] - 11s 30ms/step - loss: 0.8866 - get_f1: 0.4646 - val_loss: 0.6959 - val_get_f1: 0.5865 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.8149 - get_f1: 0.5518 - val_loss: 0.5986 - val_get_f1: 0.5955 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7927 - get_f1: 0.5682 - val_loss: 0.5759 - val_get_f1: 0.6116 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "383/383 [==============================] - 11s 29ms/step - loss: 0.7826 - get_f1: 0.5775 - val_loss: 0.5887 - val_get_f1: 0.6303 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.7781 - get_f1: 0.5877 - val_loss: 0.5756 - val_get_f1: 0.6340 - lr: 9.0484e-06\n",
      "Epoch 9/50\n",
      "383/383 [==============================] - 11s 27ms/step - loss: 0.7747 - get_f1: 0.5843 - val_loss: 0.5797 - val_get_f1: 0.6354 - lr: 8.1873e-06\n",
      "Epoch 10/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.7704 - get_f1: 0.5874 - val_loss: 0.5615 - val_get_f1: 0.6286 - lr: 7.4082e-06\n",
      "Epoch 11/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.7702 - get_f1: 0.5906 - val_loss: 0.5594 - val_get_f1: 0.6339 - lr: 6.7032e-06\n",
      "Epoch 12/50\n",
      "383/383 [==============================] - 10s 26ms/step - loss: 0.7652 - get_f1: 0.5932 - val_loss: 0.5592 - val_get_f1: 0.6451 - lr: 6.0653e-06\n",
      "Epoch 13/50\n",
      "383/383 [==============================] - 11s 29ms/step - loss: 0.7618 - get_f1: 0.5953 - val_loss: 0.5975 - val_get_f1: 0.6254 - lr: 5.4881e-06\n",
      "Epoch 14/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.7645 - get_f1: 0.5905 - val_loss: 0.5721 - val_get_f1: 0.6346 - lr: 4.9659e-06\n",
      "Epoch 15/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7603 - get_f1: 0.6014 - val_loss: 0.5568 - val_get_f1: 0.6330 - lr: 4.4933e-06\n",
      "Epoch 16/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.7588 - get_f1: 0.6003 - val_loss: 0.5660 - val_get_f1: 0.6324 - lr: 4.0657e-06\n",
      "Epoch 17/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7567 - get_f1: 0.5996 - val_loss: 0.5693 - val_get_f1: 0.6396 - lr: 3.6788e-06\n",
      "Epoch 18/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7577 - get_f1: 0.6045 - val_loss: 0.5603 - val_get_f1: 0.6331 - lr: 3.3287e-06\n",
      " 5/32 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 15:57:02.035161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 15:57:02.065058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 10ms/step\n",
      "Accuracy on own dev set: 0.727\n",
      "F1 score on dev set (macro): 0.7110423116615068\n",
      "Accuracy on dev set (macro): 0.727\n",
      "Conf Matrix:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       648\n",
      "           1       0.60      0.70      0.64       352\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.71      0.72      0.71      1000\n",
      "weighted avg       0.74      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform words to indices using a vectorizer\n",
    "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
    "# Use train and dev to create vocab - could also do just train\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
    "with tf.device('/cpu:0'):\n",
    "    vectorizer.adapt(text_ds)\n",
    "    \n",
    "# Dictionary mapping words to idx\n",
    "voc = vectorizer.get_vocabulary()\n",
    "\n",
    "# Transform input to vectorized input\n",
    "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()\n",
    "\n",
    "#Read embeddings\n",
    "embeddings_ft = read_word_emb(\"embeddings/crawl-300d-2M-subword.vec\", voc)\n",
    "\n",
    "#embeddings matrix\n",
    "emb_matrix = get_emb_matrix(voc, embeddings_ft)\n",
    "# Create model\n",
    "model = create_model(Y_train, emb_matrix, lr=0.00001)\n",
    "# Train the model\n",
    "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 32, 50)\n",
    "y_preds=test_set_predict(model, X_dev_vect, Y_dev_bin, \"dev\")\n",
    "print(\"F1 score on dev set (macro):\",f1_score(Y_dev_bin.flatten(),y_preds,average='macro'))\n",
    "print(\"Accuracy on dev set (macro):\",accuracy_score(Y_dev_bin.flatten(),y_preds))\n",
    "print(\"Conf Matrix: \", classification_report(Y_dev_bin.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b84200",
   "metadata": {},
   "source": [
    "## Split slashes and underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0aaa875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text_in):\n",
    "    '''Read in text and preprocesses it and returns'''\n",
    "    input = re.sub(\"/\",\" / \",text_in) #split slashes\n",
    "    input = re.sub(\"_\",\" \",input) #split underscores\n",
    "    return input\n",
    "\n",
    "X_train=[preprocess_input(x) for x in X_train_org]\n",
    "X_dev=[preprocess_input(x) for x in X_dev_org]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "277f9900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:06:59.742677: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:17:01.762782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 16:17:01.927801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/383 [..............................] - ETA: 10s - loss: 0.9318 - get_f1: 0.3064 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:17:02.122132: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 0s - loss: 0.9216 - get_f1: 0.3456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:17:13.572284: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 16:17:13.619438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 13s 32ms/step - loss: 0.9216 - get_f1: 0.3456 - val_loss: 0.6958 - val_get_f1: 0.3371 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "383/383 [==============================] - 11s 29ms/step - loss: 0.9201 - get_f1: 0.3696 - val_loss: 0.6982 - val_get_f1: 0.3788 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "383/383 [==============================] - 16s 41ms/step - loss: 0.9184 - get_f1: 0.4077 - val_loss: 0.6965 - val_get_f1: 0.4105 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "383/383 [==============================] - 12s 30ms/step - loss: 0.8891 - get_f1: 0.4643 - val_loss: 0.7032 - val_get_f1: 0.5737 - lr: 1.0000e-05\n",
      " 4/32 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:17:53.221227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 16:17:53.252681: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 10ms/step\n",
      "Accuracy on own dev set: 0.612\n",
      "F1 score on dev set (macro): 0.6109480034011969\n",
      "Accuracy on dev set (macro): 0.612\n",
      "Conf Matrix:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.51      0.63       648\n",
      "           1       0.47      0.80      0.59       352\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.65      0.65      0.61      1000\n",
      "weighted avg       0.70      0.61      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform words to indices using a vectorizer\n",
    "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
    "# Use train and dev to create vocab - could also do just train\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
    "with tf.device('/cpu:0'):\n",
    "    vectorizer.adapt(text_ds)\n",
    "    \n",
    "# Dictionary mapping words to idx\n",
    "voc = vectorizer.get_vocabulary()\n",
    "\n",
    "# Transform input to vectorized input\n",
    "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()\n",
    "\n",
    "#Read embeddings\n",
    "embeddings_ft = read_word_emb(\"embeddings/crawl-300d-2M-subword.vec\", voc)\n",
    "\n",
    "#embeddings matrix\n",
    "emb_matrix = get_emb_matrix(voc, embeddings_ft)\n",
    "# Create model\n",
    "model = create_model(Y_train, emb_matrix, lr=0.00001)\n",
    "# Train the model\n",
    "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 32, 50)\n",
    "y_preds=test_set_predict(model, X_dev_vect, Y_dev_bin, \"dev\")\n",
    "print(\"F1 score on dev set (macro):\",f1_score(Y_dev_bin.flatten(),y_preds,average='macro'))\n",
    "print(\"Accuracy on dev set (macro):\",accuracy_score(Y_dev_bin.flatten(),y_preds))\n",
    "print(\"Conf Matrix: \", classification_report(Y_dev_bin.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ac7d2",
   "metadata": {},
   "source": [
    "## Split hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91c72c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text_in):\n",
    "    '''Read in text and preprocesses it and returns'''\n",
    "    hashtags = re.findall(r\"(#\\w+)\", text_in) #split hashtags\n",
    "    for hs in hashtags:\n",
    "        words = \" \".join(segment(hs))\n",
    "        text_in = text_in.replace(hs, words)\n",
    "    return text_in\n",
    "\n",
    "X_train=[preprocess_input(x) for x in X_train_org]\n",
    "X_dev=[preprocess_input(x) for x in X_dev_org]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "271eec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:21:33.784758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:31:41.910461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 16:31:42.088584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/383 [..............................] - ETA: 7:52 - loss: 0.9327 - get_f1: 0.3636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:31:42.259433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 0s - loss: 0.9214 - get_f1: 0.3485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:31:54.189899: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 16:31:54.234024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 14s 33ms/step - loss: 0.9214 - get_f1: 0.3485 - val_loss: 0.6957 - val_get_f1: 0.3301 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "383/383 [==============================] - 11s 27ms/step - loss: 0.9201 - get_f1: 0.3579 - val_loss: 0.6977 - val_get_f1: 0.3549 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "383/383 [==============================] - 12s 30ms/step - loss: 0.9187 - get_f1: 0.3885 - val_loss: 0.6963 - val_get_f1: 0.3657 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "383/383 [==============================] - 11s 29ms/step - loss: 0.9013 - get_f1: 0.4348 - val_loss: 0.7304 - val_get_f1: 0.5609 - lr: 1.0000e-05\n",
      " 6/32 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:32:28.102804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 16:32:28.137900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 10ms/step\n",
      "Accuracy on own dev set: 0.607\n",
      "F1 score on dev set (macro): 0.6050088496108885\n",
      "Accuracy on dev set (macro): 0.607\n",
      "Conf Matrix:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63       648\n",
      "           1       0.46      0.76      0.58       352\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.63      0.64      0.61      1000\n",
      "weighted avg       0.68      0.61      0.61      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform words to indices using a vectorizer\n",
    "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
    "# Use train and dev to create vocab - could also do just train\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
    "with tf.device('/cpu:0'):\n",
    "    vectorizer.adapt(text_ds)\n",
    "    \n",
    "# Dictionary mapping words to idx\n",
    "voc = vectorizer.get_vocabulary()\n",
    "\n",
    "# Transform input to vectorized input\n",
    "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()\n",
    "\n",
    "#Read embeddings\n",
    "embeddings_ft = read_word_emb(\"embeddings/crawl-300d-2M-subword.vec\", voc)\n",
    "\n",
    "#embeddings matrix\n",
    "emb_matrix = get_emb_matrix(voc, embeddings_ft)\n",
    "# Create model\n",
    "model = create_model(Y_train, emb_matrix, lr=0.00001)\n",
    "# Train the model\n",
    "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 32, 50)\n",
    "y_preds=test_set_predict(model, X_dev_vect, Y_dev_bin, \"dev\")\n",
    "print(\"F1 score on dev set (macro):\",f1_score(Y_dev_bin.flatten(),y_preds,average='macro'))\n",
    "print(\"Accuracy on dev set (macro):\",accuracy_score(Y_dev_bin.flatten(),y_preds))\n",
    "print(\"Conf Matrix: \", classification_report(Y_dev_bin.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10678e4",
   "metadata": {},
   "source": [
    "## Emoji change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbb5aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text_in):\n",
    "    '''Read in text and preprocesses it and returns'''\n",
    "    input = emoji.demojize(text_in,delimiters=(\" \",\" \")) #change emoji\n",
    "    input = re.sub(\"_\",\" \",input) #split underscores\n",
    "    return input\n",
    "X_train=[preprocess_input(x) for x in X_train_org]\n",
    "X_dev=[preprocess_input(x) for x in X_dev_org]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98540873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 16:59:57.267244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:09:42.392201: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:09:42.512533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/383 [..............................] - ETA: 6:54 - loss: 0.9332 - get_f1: 0.4848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:09:42.687631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 0s - loss: 0.9215 - get_f1: 0.3603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:09:53.570228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:09:53.613838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 12s 30ms/step - loss: 0.9215 - get_f1: 0.3603 - val_loss: 0.6958 - val_get_f1: 0.3480 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.9203 - get_f1: 0.3589 - val_loss: 0.6976 - val_get_f1: 0.3557 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.9190 - get_f1: 0.3837 - val_loss: 0.6958 - val_get_f1: 0.3560 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.9077 - get_f1: 0.4270 - val_loss: 0.7793 - val_get_f1: 0.5491 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.8360 - get_f1: 0.5225 - val_loss: 0.6032 - val_get_f1: 0.5800 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.8048 - get_f1: 0.5605 - val_loss: 0.5856 - val_get_f1: 0.6019 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "383/383 [==============================] - 11s 27ms/step - loss: 0.7932 - get_f1: 0.5681 - val_loss: 0.5930 - val_get_f1: 0.6110 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7834 - get_f1: 0.5808 - val_loss: 0.5798 - val_get_f1: 0.6243 - lr: 9.0484e-06\n",
      "Epoch 9/50\n",
      "383/383 [==============================] - 11s 28ms/step - loss: 0.7761 - get_f1: 0.5867 - val_loss: 0.5856 - val_get_f1: 0.6279 - lr: 8.1873e-06\n",
      "Epoch 10/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7737 - get_f1: 0.5856 - val_loss: 0.5629 - val_get_f1: 0.6208 - lr: 7.4082e-06\n",
      "Epoch 11/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7691 - get_f1: 0.5938 - val_loss: 0.5606 - val_get_f1: 0.6302 - lr: 6.7032e-06\n",
      "Epoch 12/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7651 - get_f1: 0.5944 - val_loss: 0.5624 - val_get_f1: 0.6326 - lr: 6.0653e-06\n",
      "Epoch 13/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.7636 - get_f1: 0.5958 - val_loss: 0.5962 - val_get_f1: 0.6261 - lr: 5.4881e-06\n",
      "Epoch 14/50\n",
      "383/383 [==============================] - 10s 26ms/step - loss: 0.7614 - get_f1: 0.5940 - val_loss: 0.5727 - val_get_f1: 0.6349 - lr: 4.9659e-06\n",
      " 5/32 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:12:09.999823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:12:10.030818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 11ms/step\n",
      "Accuracy on own dev set: 0.712\n",
      "F1 score on dev set (macro): 0.70024854391567\n",
      "Accuracy on dev set (macro): 0.712\n",
      "Conf Matrix:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       648\n",
      "           1       0.57      0.73      0.64       352\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.70      0.72      0.70      1000\n",
      "weighted avg       0.74      0.71      0.72      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform words to indices using a vectorizer\n",
    "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
    "# Use train and dev to create vocab - could also do just train\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
    "with tf.device('/cpu:0'):\n",
    "    vectorizer.adapt(text_ds)\n",
    "    \n",
    "# Dictionary mapping words to idx\n",
    "voc = vectorizer.get_vocabulary()\n",
    "\n",
    "# Transform input to vectorized input\n",
    "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()\n",
    "\n",
    "#Read embeddings\n",
    "embeddings_ft = read_word_emb(\"embeddings/crawl-300d-2M-subword.vec\", voc)\n",
    "\n",
    "#embeddings matrix\n",
    "emb_matrix = get_emb_matrix(voc, embeddings_ft)\n",
    "# Create model\n",
    "model = create_model(Y_train, emb_matrix, lr=0.00001)\n",
    "# Train the model\n",
    "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 32, 50)\n",
    "y_preds=test_set_predict(model, X_dev_vect, Y_dev_bin, \"dev\")\n",
    "print(\"F1 score on dev set (macro):\",f1_score(Y_dev_bin.flatten(),y_preds,average='macro'))\n",
    "print(\"Accuracy on dev set (macro):\",accuracy_score(Y_dev_bin.flatten(),y_preds))\n",
    "print(\"Conf Matrix: \", classification_report(Y_dev_bin.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b58710",
   "metadata": {},
   "source": [
    "## Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba1ccc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text_in):\n",
    "    '''Read in text and preprocesses it and returns'''\n",
    "    return text_in.lower()\n",
    "X_train=[preprocess_input(x) for x in X_train_org]\n",
    "X_dev=[preprocess_input(x) for x in X_dev_org]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64753e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:27:12.663333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:35:48.424778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:35:48.567411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/383 [..............................] - ETA: 7:53 - loss: 0.9292 - get_f1: 0.3571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:35:48.779442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 0s - loss: 0.9217 - get_f1: 0.3491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:35:59.561326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:35:59.611363: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 13s 30ms/step - loss: 0.9217 - get_f1: 0.3491 - val_loss: 0.6957 - val_get_f1: 0.3562 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.9198 - get_f1: 0.3773 - val_loss: 0.6988 - val_get_f1: 0.3824 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "383/383 [==============================] - 10s 26ms/step - loss: 0.9180 - get_f1: 0.4002 - val_loss: 0.6960 - val_get_f1: 0.3540 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "383/383 [==============================] - 10s 27ms/step - loss: 0.9044 - get_f1: 0.4284 - val_loss: 0.7600 - val_get_f1: 0.5468 - lr: 1.0000e-05\n",
      " 6/32 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:36:30.988334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:36:31.020493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 10ms/step\n",
      "Accuracy on own dev set: 0.593\n",
      "F1 score on dev set (macro): 0.5910530033489443\n",
      "Accuracy on dev set (macro): 0.593\n",
      "Conf Matrix:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62       648\n",
      "           1       0.45      0.74      0.56       352\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.62      0.63      0.59      1000\n",
      "weighted avg       0.67      0.59      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform words to indices using a vectorizer\n",
    "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
    "# Use train and dev to create vocab - could also do just train\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
    "with tf.device('/cpu:0'):\n",
    "    vectorizer.adapt(text_ds)\n",
    "    \n",
    "# Dictionary mapping words to idx\n",
    "voc = vectorizer.get_vocabulary()\n",
    "\n",
    "# Transform input to vectorized input\n",
    "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()\n",
    "\n",
    "#Read embeddings\n",
    "embeddings_ft = read_word_emb(\"embeddings/crawl-300d-2M-subword.vec\", voc)\n",
    "\n",
    "#embeddings matrix\n",
    "emb_matrix = get_emb_matrix(voc, embeddings_ft)\n",
    "# Create model\n",
    "model = create_model(Y_train, emb_matrix, lr=0.00001)\n",
    "# Train the model\n",
    "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 32, 50)\n",
    "y_preds=test_set_predict(model, X_dev_vect, Y_dev_bin, \"dev\")\n",
    "print(\"F1 score on dev set (macro):\",f1_score(Y_dev_bin.flatten(),y_preds,average='macro'))\n",
    "print(\"Accuracy on dev set (macro):\",accuracy_score(Y_dev_bin.flatten(),y_preds))\n",
    "print(\"Conf Matrix: \", classification_report(Y_dev_bin.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1fd382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
