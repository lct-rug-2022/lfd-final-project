{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "523f4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Embedding, LSTM, Dropout, Bidirectional, MaxPooling1D, Conv1D\n",
    "from keras.initializers import Constant\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fde3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "preprocess-twitter.py\n",
    "python preprocess-twitter.py \"Some random text with #hashtags, @mentions and http://t.co/kdjfkdjf (links). :)\"\n",
    "Script for preprocessing tweets by Romain Paulus\n",
    "with small modifications by Jeffrey Pennington\n",
    "with translation to Python by Motoki Wu\n",
    "Translation of Ruby script to create features for GloVe vectors for Twitter data.\n",
    "http://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "\"\"\"\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body)\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "    ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n",
    "    # text = re_sub(r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f450afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(corpus_file):\n",
    "    '''Read in data set and returns docs and labels'''\n",
    "    documents = []\n",
    "    labels = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip()\n",
    "            documents.append(tokens.split(\"\\t\")[0])\n",
    "            # binary problem: NOT, OFF\n",
    "            labels.append(tokens.split(\"\\t\")[1])\n",
    "    return documents, labels\n",
    "\n",
    "def read_word_emb(embeddings_file,voc):\n",
    "    '''Read embeddings dictionary file'''\n",
    "    fin = io.open(embeddings_file, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in voc:\n",
    "            data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "    return data\n",
    "\n",
    "def get_emb_matrix(voc, emb):\n",
    "    '''Get embedding matrix given vocab and the embeddings'''\n",
    "    num_tokens = len(voc) + 2\n",
    "    word_index = dict(zip(voc, range(len(voc))))\n",
    "    # Bit hacky, get embedding dimension from the word \"the\"\n",
    "    embedding_dim = len(emb[\"the\"])\n",
    "    # Prepare embedding matrix to the correct size\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = emb.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    # Final matrix with pretrained embeddings that we can feed to embedding layer\n",
    "    return embedding_matrix\n",
    "\n",
    "def test_set_predict(model, X_test, Y_test, ident):\n",
    "    '''Do predictions and measure accuracy on our own test set (that we split off train)'''\n",
    "    # Get predictions using the trained model\n",
    "    Y_pred = model.predict(X_test)\n",
    "    # Finally, convert to labels to get scores with sklearn\n",
    "    Y_pred=(Y_pred.flatten()>0.5)*1\n",
    "    # If you have gold data, you can calculate accuracy\n",
    "    Y_test = Y_test.flatten()\n",
    "    print('Accuracy on own {1} set: {0}'.format(round(accuracy_score(Y_test, Y_pred), 3), ident))\n",
    "    return Y_pred\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    '''for getting f1 scores during training'''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    '''learning rate scheduler'''\n",
    "    if epoch < 7:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "def train_model(model, X_train, Y_train, X_dev, Y_dev, batch_size, epochs):\n",
    "    '''Train the model here'''\n",
    "    verbose = 1\n",
    "    batch_size = batch_size\n",
    "    epochs = epochs\n",
    "    # Early stopping\n",
    "    callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    #Learning rate scheduler using function\n",
    "    callback2 = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    #Assigning class weights for imbalanced classification\n",
    "    class_weight = {0: 1.,\n",
    "                1: 2.}\n",
    "    # Finally fit the model to our data\n",
    "    model.fit(X_train, Y_train, verbose=verbose, epochs=epochs, callbacks=[callback1,callback2], batch_size=batch_size, validation_data=(X_dev, Y_dev),\n",
    "             class_weight=class_weight)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14ce159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting seeds for reproducibility\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "python_random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9dfba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:45:14.474998: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "X_train, Y_train = read_corpus(\"datasets/train.tsv\")\n",
    "X_dev, Y_dev = read_corpus(\"datasets/val.tsv\")\n",
    "\n",
    "X_train = [tokenize(x) for x in X_train]\n",
    "X_dev = [tokenize(x) for x in X_dev]\n",
    "\n",
    "# Transform words to indices using a vectorizer\n",
    "vectorizer = TextVectorization(standardize=None, output_sequence_length=50)\n",
    "# Use train and dev to create vocab - could also do just train\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train + X_dev)\n",
    "with tf.device('/cpu:0'):\n",
    "    vectorizer.adapt(text_ds)\n",
    "    \n",
    "# Dictionary mapping words to idx\n",
    "voc = vectorizer.get_vocabulary()\n",
    "\n",
    "#changing labels to binary\n",
    "encoder = LabelBinarizer()\n",
    "Y_train_bin = encoder.fit_transform(Y_train)  # Use encoder.classes_ to find mapping back\n",
    "Y_dev_bin = encoder.fit_transform(Y_dev)\n",
    "\n",
    "# Transform input to vectorized input\n",
    "X_train_vect = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_dev_vect = vectorizer(np.array([[s] for s in X_dev])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b24daad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best model architecture used after experimenting\n",
    "def create_model(Y_train, emb_matrix, lr):\n",
    "    '''Create the Keras model to use'''\n",
    "    \n",
    "    loss_function = 'binary_crossentropy'\n",
    "    optim = Adam(learning_rate=lr)\n",
    "    \n",
    "    # Take embedding dim and size from emb_matrix\n",
    "    embedding_dim = len(emb_matrix[0])\n",
    "    num_tokens = len(emb_matrix)\n",
    "    \n",
    "    # Now build the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_tokens, embedding_dim, embeddings_initializer=Constant(emb_matrix),trainable=False))\n",
    "    model.add(LSTM(embedding_dim, dropout=0.2))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    # Compile model using our settings, check for accuracy\n",
    "    model.compile(loss=loss_function, optimizer=optim, metrics=[get_f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73c04512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:49:34.577470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:49:34.682585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/383 [..............................] - ETA: 10s - loss: 0.9308 - get_f1: 0.4664 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:49:34.850336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - ETA: 0s - loss: 0.9205 - get_f1: 0.3207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:49:42.099417: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:49:42.140137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383/383 [==============================] - 9s 20ms/step - loss: 0.9205 - get_f1: 0.3207 - val_loss: 0.6873 - val_get_f1: 0.2837 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.8627 - get_f1: 0.4601 - val_loss: 0.5828 - val_get_f1: 0.5915 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7898 - get_f1: 0.5821 - val_loss: 0.5724 - val_get_f1: 0.6127 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "383/383 [==============================] - 8s 20ms/step - loss: 0.7747 - get_f1: 0.5822 - val_loss: 0.6485 - val_get_f1: 0.6041 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7649 - get_f1: 0.5965 - val_loss: 0.5717 - val_get_f1: 0.6145 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "383/383 [==============================] - 7s 18ms/step - loss: 0.7644 - get_f1: 0.5953 - val_loss: 0.5688 - val_get_f1: 0.6167 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7557 - get_f1: 0.6052 - val_loss: 0.6211 - val_get_f1: 0.6216 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7533 - get_f1: 0.6042 - val_loss: 0.5431 - val_get_f1: 0.6080 - lr: 9.0484e-05\n",
      "Epoch 9/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7484 - get_f1: 0.6034 - val_loss: 0.5686 - val_get_f1: 0.6318 - lr: 8.1873e-05\n",
      "Epoch 10/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7463 - get_f1: 0.6016 - val_loss: 0.5351 - val_get_f1: 0.6193 - lr: 7.4082e-05\n",
      "Epoch 11/50\n",
      "383/383 [==============================] - 7s 18ms/step - loss: 0.7414 - get_f1: 0.6136 - val_loss: 0.5373 - val_get_f1: 0.6151 - lr: 6.7032e-05\n",
      "Epoch 12/50\n",
      "383/383 [==============================] - 8s 20ms/step - loss: 0.7370 - get_f1: 0.6116 - val_loss: 0.5389 - val_get_f1: 0.6168 - lr: 6.0653e-05\n",
      "Epoch 13/50\n",
      "383/383 [==============================] - 7s 19ms/step - loss: 0.7376 - get_f1: 0.6140 - val_loss: 0.6223 - val_get_f1: 0.6240 - lr: 5.4881e-05\n",
      " 8/32 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 17:51:10.079973: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-03 17:51:10.109230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 9ms/step\n",
      "Accuracy on own dev set: 0.661\n",
      "F1 score on dev set (macro): 0.658978081042501\n",
      "Accuracy on dev set (macro): 0.661\n",
      "Conf Matrix:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.57      0.69       648\n",
      "           1       0.51      0.83      0.63       352\n",
      "\n",
      "    accuracy                           0.66      1000\n",
      "   macro avg       0.69      0.70      0.66      1000\n",
      "weighted avg       0.74      0.66      0.67      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read embeddings\n",
    "embeddings_ft = read_word_emb(\"embeddings/glove.twitter.27B.100d.txt\", voc)\n",
    "#embeddings matrix\n",
    "emb_matrix = get_emb_matrix(voc, embeddings_ft)\n",
    "# Create model\n",
    "model = create_model(Y_train, emb_matrix, lr=0.0001)\n",
    "# Train the model\n",
    "model = train_model(model, X_train_vect, Y_train_bin, X_dev_vect, Y_dev_bin, 32, 50)\n",
    "y_preds=test_set_predict(model, X_dev_vect, Y_dev_bin, \"dev\")\n",
    "print(\"F1 score on dev set (macro):\",f1_score(Y_dev_bin.flatten(),y_preds,average='macro'))\n",
    "print(\"Accuracy on dev set (macro):\",accuracy_score(Y_dev_bin.flatten(),y_preds))\n",
    "print(\"Conf Matrix: \", classification_report(Y_dev_bin.flatten(), y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47815650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f051c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35a25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097aedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
