{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac2e932-f3f0-4770-9e30-2b43570fcfd4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "060fa240-b3ce-4cb7-8a95-7ed8cd4e5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import typing as tp\n",
    "from collections.abc import Callable\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d03b283e-4e42-4970-8bf0-ea12f51f9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"  # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ba9e6-c7c6-44b6-9f56-a56506bc2c47",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f516b5a-08ed-461f-9a59-6cff965f8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FOLDER = Path('.')\n",
    "DATA_FOLDER = Path('../datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb74c532-61e8-4b03-9ce6-634732a7cd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12240, 1000, 860)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_FOLDER / 'train.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "df_val = pd.read_csv(DATA_FOLDER / 'val.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "df_test = pd.read_csv(DATA_FOLDER / 'test.tsv', sep='\\t', header=None, names=['text', 'label'])\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9cb8f4-d3da-4849-86e8-64730b567b83",
   "metadata": {},
   "source": [
    "## Auxiliary functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97c5abf6-3cfd-4ef2-991c-ec8cd06b1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_split(\n",
    "        model: BaseEstimator,\n",
    "        data_train: list,\n",
    "        target_train: list,\n",
    "        data_val: list,\n",
    "        target_val: list,\n",
    "        scorer: Callable[[tp.Any, tp.Any], float],\n",
    ") -> dict[str, tp.Any]:\n",
    "    \"\"\"Fit predict model on current split\n",
    "    :param model: Model to be trained\n",
    "    :param data_train: train data to perform k-fold cv\n",
    "    :param target_train: target train data\n",
    "    :param data_val: validate data to scoring\n",
    "    :param target_val: validate target to scoring\n",
    "    :param scorer: function to score prediction. args: target, prediction\n",
    "    :return: dict with results of cv\n",
    "    \"\"\"\n",
    "    data_train, data_val = np.array(data_train), np.array(data_val)\n",
    "    target_train, target_val = np.array(target_train), np.array(target_val)\n",
    "\n",
    "    # Fit model in current fold\n",
    "    start_time = time.time()\n",
    "    model.fit(data_train, target_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # predict for out-fold and save it for validation\n",
    "    pred_val = model.predict(data_val)\n",
    "\n",
    "    # Score for out-fold\n",
    "    score_fold = scorer(target_val, pred_val)\n",
    "\n",
    "    return {\n",
    "        'pred_val': pred_val,\n",
    "        'score': score_fold,\n",
    "        'time': end_time - start_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78ff093a-aa7a-42e0-8869-2b05a7540d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_kfold(\n",
    "        model: BaseEstimator,\n",
    "        data: list,\n",
    "        target: list,\n",
    "        scorer: Callable[[tp.Any, tp.Any], float],\n",
    "        k: int = 5,\n",
    "        *,\n",
    "        random_state: int = 42,\n",
    ") -> dict[str, tp.Any]:\n",
    "    \"\"\"Fit predict model multiple times with k-fold cross validation\n",
    "    :param model: Model to be trained\n",
    "    :param data: train data to perform k-fold cv\n",
    "    :param target: target train data\n",
    "    :param scorer: function to score prediction. args: target, prediction\n",
    "    :param k: number of folds in cross validation\n",
    "    :param random_state: fixed random state\n",
    "    :return: dict with results of cv\n",
    "    \"\"\"\n",
    "    random_instance = np.random.RandomState(random_state)\n",
    "\n",
    "    data = np.array(data)\n",
    "    target = np.array(target)\n",
    "\n",
    "    pred_train = np.empty(data.shape[0], dtype=data.dtype)\n",
    "\n",
    "    mean_score = 0\n",
    "    full_oof_score, split_oof_score = [], []\n",
    "    times = []\n",
    "\n",
    "    pred_split_train = np.empty(data.shape[0], dtype=data.dtype)\n",
    "    full_oof_score.append([])\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_instance)\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(data)):\n",
    "        # select current train/val split\n",
    "        data_train, data_val = data[train_index], data[val_index]\n",
    "        target_train, target_val = target[train_index], target[val_index]\n",
    "\n",
    "        # Fit model in current fold\n",
    "        model_fold = deepcopy(model)\n",
    "        fold_result = train_validate_split(\n",
    "            model_fold,\n",
    "            data_train, target_train,\n",
    "            data_val, target_val,\n",
    "            scorer,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        times.append(fold_result['time'])\n",
    "        pred_val = fold_result['pred_val']\n",
    "        score_fold = fold_result['score']\n",
    "\n",
    "        # save for out-fold validation\n",
    "        pred_train[val_index] = pred_val\n",
    "        pred_split_train[val_index] = pred_val\n",
    "\n",
    "        # Score for out-fold\n",
    "        mean_score += score_fold / float(k)\n",
    "        full_oof_score[-1].append(score_fold)\n",
    "\n",
    "        split_oof_score.append(scorer(target, pred_split_train))\n",
    "\n",
    "    return {\n",
    "        'train_pred': pred_train,\n",
    "        'mean_score': mean_score,\n",
    "        'mean_oof_score': np.mean(split_oof_score),\n",
    "        'oof_scores': split_oof_score,\n",
    "        'full_oof_scores': full_oof_score,\n",
    "        'oof_score': scorer(target, pred_train),\n",
    "        'times': times,\n",
    "        'mean_time': np.mean(times),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97094896-94db-426c-897f-8479575fa806",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34128247-b7cb-47ee-83b2-128f318f28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'Count': CountVectorizer(),\n",
    "    'Tfidf': TfidfVectorizer(),\n",
    "    'Hashing': HashingVectorizer(),\n",
    "}\n",
    "models = {\n",
    "    'LogReg': LogisticRegression(),\n",
    "    'SVM': SVC(),\n",
    "    'LinearSVM': LinearSVC(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'NaiveBayes': MultinomialNB(),\n",
    "    'KNeighbors': KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dccd0ee2-e3fc-491a-a868-86c693034691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vectorizer:   0%|                                                                                                 | 0/3 [00:00<?, ?it/s]\n",
      "models:   0%|                                                                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "models:  14%|█████████████▎                                                                               | 1/7 [00:00<00:03,  1.66it/s]\u001b[A\n",
      "models:  29%|██████████████████████████▌                                                                  | 2/7 [00:23<01:07, 13.49s/it]\u001b[A\n",
      "models:  43%|███████████████████████████████████████▊                                                     | 3/7 [00:24<00:30,  7.75s/it]\u001b[A\n",
      "models:  57%|█████████████████████████████████████████████████████▏                                       | 4/7 [00:37<00:29,  9.92s/it]\u001b[A\n",
      "models:  71%|██████████████████████████████████████████████████████████████████▍                          | 5/7 [00:39<00:14,  7.26s/it]\u001b[A\n",
      "models:  86%|███████████████████████████████████████████████████████████████████████████████▋             | 6/7 [00:40<00:04,  4.87s/it]\u001b[A\n",
      "models: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:40<00:00,  5.83s/it]\u001b[A\n",
      "vectorizer:  33%|█████████████████████████████▋                                                           | 1/3 [00:40<01:21, 40.82s/it]\n",
      "models:   0%|                                                                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "models:  14%|█████████████▎                                                                               | 1/7 [00:00<00:03,  1.87it/s]\u001b[A\n",
      "models:  29%|██████████████████████████▌                                                                  | 2/7 [00:43<02:06, 25.34s/it]\u001b[A\n",
      "models:  43%|███████████████████████████████████████▊                                                     | 3/7 [00:43<00:55, 13.92s/it]\u001b[A\n",
      "models:  57%|█████████████████████████████████████████████████████▏                                       | 4/7 [00:54<00:38, 12.92s/it]\u001b[A\n",
      "models:  71%|██████████████████████████████████████████████████████████████████▍                          | 5/7 [01:00<00:20, 10.39s/it]\u001b[A\n",
      "models:  86%|███████████████████████████████████████████████████████████████████████████████▋             | 6/7 [01:01<00:06,  6.95s/it]\u001b[A\n",
      "models: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [01:01<00:00,  8.81s/it]\u001b[A\n",
      "vectorizer:  67%|███████████████████████████████████████████████████████████▎                             | 2/3 [01:42<00:53, 53.09s/it]\n",
      "models:   0%|                                                                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "models:  14%|█████████████▎                                                                               | 1/7 [00:11<01:09, 11.53s/it]\u001b[A\n",
      "models:  29%|██████████████████████████▌                                                                  | 2/7 [00:46<02:07, 25.54s/it]\u001b[A\n",
      "models:  43%|███████████████████████████████████████▊                                                     | 3/7 [00:47<00:56, 14.00s/it]\u001b[A\n",
      "models:  57%|████████████████████████████████████████████████████▌                                       | 4/7 [15:54<18:19, 366.65s/it]\u001b[A\n",
      "models:  71%|█████████████████████████████████████████████████████████████████▋                          | 5/7 [16:28<08:13, 246.75s/it]\u001b[A\n",
      "models:  86%|██████████████████████████████████████████████████████████████████████████████▊             | 6/7 [16:28<02:42, 162.92s/it]\u001b[A\n",
      "models: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [16:29<00:00, 141.33s/it]\u001b[A\n",
      "vectorizer: 100%|████████████████████████████████████████████████████████████████████████████████████████| 3/3 [18:11<00:00, 363.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 49s, sys: 16.7 s, total: 19min 5s\n",
      "Wall time: 18min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df_scores = pd.DataFrame(columns=vectorizers.keys(), index=models.keys())\n",
    "df_time = pd.DataFrame(columns=vectorizers.keys(), index=models.keys())\n",
    "scorer = lambda *x: metrics.accuracy_score(*x)\n",
    "scorer = lambda *x: metrics.f1_score(*x, average='macro')\n",
    "\n",
    "\n",
    "joblib_memory = joblib.Memory()\n",
    "for vec_name, vec in tqdm(vectorizers.items(), total=len(vectorizers), desc='vectorizer'):\n",
    "    for model_name, model in tqdm(models.items(), total=len(models), desc='models'):\n",
    "        pipeline = Pipeline(\n",
    "            steps=[\n",
    "                ('vec', vec),\n",
    "                ('cls', model)\n",
    "            ],\n",
    "            memory=joblib_memory,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "        #     kfold_result = cv_kfold(pipeline, df_train['text'], df_train['label'], scorer=scorer, k=5)\n",
    "        #     df_scores.loc[model_name, vec_name] = kfold_result['oof_score']\n",
    "        #     df_time.loc[model_name, vec_name] = kfold_result['mean_time']\n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split(df_train['text'], df_train['label'])\n",
    "            validate_results = train_validate_split(pipeline, df_train['text'], df_train['label'], df_val['text'], df_val['label'], scorer, verbose=0)\n",
    "            df_scores.loc[model_name, vec_name] = validate_results['score']\n",
    "            df_time.loc[model_name, vec_name] = validate_results['time']\n",
    "        except Exception as e:\n",
    "            df_scores.loc[model_name, vec_name] = None\n",
    "            df_time.loc[model_name, vec_name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "189eef44-308a-452b-99a5-24787833c207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Tfidf</th>\n",
       "      <th>Hashing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.689854</td>\n",
       "      <td>0.676762</td>\n",
       "      <td>0.639036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.612472</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.633952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM</th>\n",
       "      <td>0.691414</td>\n",
       "      <td>0.695577</td>\n",
       "      <td>0.679687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.669319</td>\n",
       "      <td>0.671942</td>\n",
       "      <td>0.563775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.63987</td>\n",
       "      <td>0.633718</td>\n",
       "      <td>0.633318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.662126</td>\n",
       "      <td>0.504388</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.514452</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.558429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Count     Tfidf   Hashing\n",
       "LogReg            0.689854  0.676762  0.639036\n",
       "SVM               0.612472     0.664  0.633952\n",
       "LinearSVM         0.691414  0.695577  0.679687\n",
       "RandomForest      0.669319  0.671942  0.563775\n",
       "GradientBoosting   0.63987  0.633718  0.633318\n",
       "NaiveBayes        0.662126  0.504388      None\n",
       "KNeighbors        0.514452  0.592787  0.558429"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "634af58b-15c8-4a4f-9f3a-7fb251803f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\text{LogReg} & 0.690 & 0.677 & 0.639 \\\\\n",
      "\\text{SVM} & 0.612 & 0.664 & 0.634 \\\\\n",
      "\\text{LinearSVM} & 0.691 & 0.696 & 0.680 \\\\\n",
      "\\text{RandomForest} & 0.669 & 0.672 & 0.564 \\\\\n",
      "\\text{GradientBoosting} & 0.640 & 0.634 & 0.633 \\\\\n",
      "\\text{NaiveBayes} & 0.662 & 0.504 & - \\\\\n",
      "\\text{KNeighbors} & 0.514 & 0.593 & 0.558 \\\\\n"
     ]
    }
   ],
   "source": [
    "for r in df_scores.iterrows():\n",
    "    print(r'\\text{' + r[0] + '}', '&', ' & '.join(f'{i:.3f}' if i else '-' for i in r[1]), r'\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9cdb4e4-d5bd-4ec1-be3e-2a99bfc7378c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Tfidf</th>\n",
       "      <th>Hashing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.571754</td>\n",
       "      <td>0.500931</td>\n",
       "      <td>11.501481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>21.151801</td>\n",
       "      <td>41.121188</td>\n",
       "      <td>33.87945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVM</th>\n",
       "      <td>0.890761</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.241149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>13.13926</td>\n",
       "      <td>11.265821</td>\n",
       "      <td>906.895696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>2.507715</td>\n",
       "      <td>5.887582</td>\n",
       "      <td>34.143957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.227256</td>\n",
       "      <td>0.232428</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.22036</td>\n",
       "      <td>0.212619</td>\n",
       "      <td>0.16012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count      Tfidf     Hashing\n",
       "LogReg             0.571754   0.500931   11.501481\n",
       "SVM               21.151801  41.121188    33.87945\n",
       "LinearSVM          0.890761   0.290308    0.241149\n",
       "RandomForest       13.13926  11.265821  906.895696\n",
       "GradientBoosting   2.507715   5.887582   34.143957\n",
       "NaiveBayes         0.227256   0.232428        None\n",
       "KNeighbors          0.22036   0.212619     0.16012"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
