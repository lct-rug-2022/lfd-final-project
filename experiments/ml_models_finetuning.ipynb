{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "KaKREBe7gV_k",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcKcznqGhuG4",
    "outputId": "e8972da1-b2b4-4b37-9f0e-cbec63f9791e"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q hyperopt scikit-optimize git+https://github.com/hyperopt/hyperopt-sklearn pandas sklearn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RKoIP3v_gV_n"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from hyperopt import tpe\n",
    "from hpsklearn import HyperoptEstimator, linear_svc, tfidf, any_sparse_classifier, random_forest_classifier, extra_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AyWxLbJVgV_o"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"  # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "aztgAmOJgV_p",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FOLDER = Path('.')\n",
    "DATA_FOLDER = Path('../datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4V7SRiXu8ZR",
    "outputId": "a6568e01-de9f-4874-dc80-1709a3fef6a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(12240, 1000, 860)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_FOLDER / 'train_preprocessed.csv')\n",
    "df_val = pd.read_csv(DATA_FOLDER / 'val_preprocessed.csv')\n",
    "df_test = pd.read_csv(DATA_FOLDER / 'test_preprocessed.csv')\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "MdI3eEMOgV_q",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mZifzuCgV_q",
    "outputId": "beffc29f-2b0a-4533-87d5-3ef7e65dc400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.30s/trial, best loss: 0.33129084967320266]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  3.23s/trial, best loss: 0.2691993464052288]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00, 12.37s/trial, best loss: 0.2691993464052288]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:52<00:00, 52.76s/trial, best loss: 0.2691993464052288]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  4.23s/trial, best loss: 0.26511437908496727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  3.37s/trial, best loss: 0.26511437908496727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:09<00:00,  9.47s/trial, best loss: 0.26511437908496727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  8.85s/trial, best loss: 0.26511437908496727]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:07<00:00,  7.44s/trial, best loss: 0.2577614379084967]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:38<00:00, 38.75s/trial, best loss: 0.2577614379084967]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:26<00:00, 26.43s/trial, best loss: 0.2577614379084967]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:58<00:00, 118.71s/trial, best loss: 0.2577614379084967]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:04<00:00,  4.11s/trial, best loss: 0.2577614379084967]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  7.92s/trial, best loss: 0.2577614379084967]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  2.93s/trial, best loss: 0.2577614379084967]\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/16 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kblack/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kblack/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kblack/Projects/rug/lfd-final-project/.venv/lib/python3.10/site-packages/hpsklearn/estimator/_cost_fn.py\", line 199, in _cost_fn\n",
      "    learner.fit(XEXfit, yfit)\n",
      "  File \"/Users/kblack/Projects/rug/lfd-final-project/.venv/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/kblack/Projects/rug/lfd-final-project/.venv/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1205, in _fit_liblinear\n",
      "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:26<00:00, 26.18s/trial, best loss: 0.2577614379084967]\n",
      "CPU times: user 6.81 s, sys: 993 ms, total: 7.81 s\n",
      "Wall time: 6min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learner': LinearSVC(C=1.281113557643012, intercept_scaling=1.4929904983561797,\n",
       "           max_iter=1129, random_state=2, tol=0.0020463026535875875),\n",
       " 'preprocs': (TfidfVectorizer(ngram_range=(1, 3), norm=None, smooth_idf=False, use_idf=False),),\n",
       " 'ex_preprocs': ()}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estim = HyperoptEstimator(\n",
    "    classifier=linear_svc('model'),\n",
    "    preprocessing=[tfidf('tfidf')],\n",
    "    algo=tpe.suggest,\n",
    "    trial_timeout=60*60*60,\n",
    "    n_jobs=8,\n",
    "    max_evals=64,\n",
    ")\n",
    "\n",
    "estim.fit(df_train['tweet'], df_train['label'], cv_shuffle=True)\n",
    "estim.best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(ngram_range=(1, 3), norm=None, smooth_idf=False, use_idf=False)),\n",
    "    ('model', LinearSVC(C=1.2811, intercept_scaling=1.4929,\n",
    "           max_iter=1129, random_state=2, tol=0.0021)),\n",
    "]).fit(df_train['tweet'], df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1-macro score: 0.7048320785167118\n",
      "test acc      score: 0.7813953488372093\n"
     ]
    }
   ],
   "source": [
    "print('test f1-macro score:', metrics.f1_score(df_test['label'], test_pipeline.predict(df_test['tweet']), average='macro'))\n",
    "print('test acc      score:', metrics.accuracy_score(df_test['label'], test_pipeline.predict(df_test['tweet'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.4 ms Â± 3.64 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test_pipeline.predict(df_test['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "aXgxe3_rgV_r",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4BffL1_gV_r",
    "outputId": "0d769bf0-9223-4771-acb6-c6b7b243bb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "cv acc score: 0.7059565272316684\n",
      "Pipeline(steps=[('vec',\n",
      "                 TfidfVectorizer(max_df=0.9719971271707429, min_df=0.0,\n",
      "                                 ngram_range=(1, 2), stop_words='english',\n",
      "                                 sublinear_tf=True)),\n",
      "                ('model',\n",
      "                 LinearSVC(C=2.3090870203258773, tol=0.0055917094329699935))])\n",
      "CPU times: user 6min 45s, sys: 1min 21s, total: 8min 7s\n",
      "Wall time: 5min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": "OrderedDict([('model__C', 2.3090870203258773),\n             ('model__loss', 'squared_hinge'),\n             ('model__tol', 0.0055917094329699935),\n             ('vec__lowercase', True),\n             ('vec__max_df', 0.9719971271707429),\n             ('vec__min_df', 0.0),\n             ('vec__ngram_range', (1, 2)),\n             ('vec__norm', 'l2'),\n             ('vec__stop_words', 'english'),\n             ('vec__sublinear_tf', True)])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('model', LinearSVC()),\n",
    "])\n",
    "\n",
    "\n",
    "# can not use tuples for `vec__ngram_range`, due to https://github.com/scikit-optimize/scikit-optimize/issues/967\n",
    "class MyTuple:\n",
    "    def __init__(self, *tp):\n",
    "        self.tp = tp\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.tp)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.tp)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.tp.__repr__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.tp.__str__()\n",
    "\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    pipeline,\n",
    "    {\n",
    "        'vec__lowercase': [True, False],\n",
    "        'vec__stop_words': [None, 'english'],\n",
    "        'vec__ngram_range': Categorical([MyTuple(1,1), MyTuple(1,2), MyTuple(1,3), MyTuple(2,2), MyTuple(2,3)], transform='identity'),\n",
    "        'vec__norm': ['l1', 'l2'],\n",
    "        'vec__sublinear_tf': [True, False],\n",
    "        'vec__max_df': (0.9, 1.0, 'uniform'),\n",
    "        'vec__min_df': (0.0, 0.1, 'uniform'),\n",
    "     \n",
    "        'model__C': (1e-6, 1e+6, 'log-uniform'),\n",
    "        'model__tol': (1e-6, 1e-2, 'log-uniform'),\n",
    "        'model__loss': ['hinge', 'squared_hinge'],\n",
    "    },\n",
    "    n_iter=64,\n",
    "    cv=4,\n",
    "    n_jobs=4,\n",
    "    scoring='f1_macro',\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "opt.fit(df_train['tweet'], df_train['label'])\n",
    "\n",
    "print('cv acc score:', opt.best_score_)\n",
    "print(str(opt.best_estimator_))\n",
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "id": "__szMvkfgV_s",
    "outputId": "9fca91df-5557-4c9e-dda7-75de4e69cac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val f1 score: 0.696657161924407\n"
     ]
    }
   ],
   "source": [
    "print('val f1 score:', opt.score(df_val['tweet'], df_val['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val f1  score: 0.8113207547169812\n",
      "val acc score: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('val f1  score:', metrics.f1_score(df_val['label'], opt.best_estimator_.predict(df_val['tweet']), average='binary', pos_label='NOT'))\n",
    "print('val acc score:', metrics.accuracy_score(df_val['label'], opt.best_estimator_.predict(df_val['tweet'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_k4pVXrPbR2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val f1  score: 0.7948717948717949\n",
      "val acc score: 0.728\n"
     ]
    }
   ],
   "source": [
    "print('val f1  score:', metrics.f1_score(df_val['label'], opt.best_estimator_.predict(df_val['tweet']), average='binary', pos_label='NOT'))\n",
    "print('val acc score:', metrics.accuracy_score(df_val['label'], opt.best_estimator_.predict(df_val['tweet'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(max_df=0.9719, min_df=0.0,\n",
    "                                 ngram_range=(1, 2), stop_words='english',\n",
    "                                 sublinear_tf=True)),\n",
    "    ('model', LinearSVC(C=2.3091, tol=0.0056))\n",
    "]).fit(df_train['tweet'], df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test f1-macro score: 0.7468693544833663\n",
      "test acc      score: 0.8058139534883721\n"
     ]
    }
   ],
   "source": [
    "print('test f1-macro score:', metrics.f1_score(df_test['label'], test_pipeline.predict(df_test['tweet']), average='macro'))\n",
    "print('test acc      score:', metrics.accuracy_score(df_test['label'], test_pipeline.predict(df_test['tweet'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[554,  66],\n       [101, 139]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(df_test['label'], test_pipeline.predict(df_test['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.85      0.89      0.87       620\n",
      "         OFF       0.68      0.58      0.62       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.76      0.74      0.75       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(df_test['label'], test_pipeline.predict(df_test['tweet'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.7 ms Â± 16.4 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "test_pipeline.predict(df_test['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 tweet  \\\n0                     @user @user you are so beautiful   \n1    @user he is not a troll he is simply dumb but ...   \n2    @user i understand annie she is stuck in betwe...   \n3    @user @user hillary was blaming women not too ...   \n4    @user @user i support jahs blessings on his hu...   \n..                                                 ...   \n995  @user sometimes i get strong vibes from people...   \n996  benidorm  check mark button   creamfields  che...   \n997  @user and why report this garbage.  we don't g...   \n998                                        @user pussy   \n999  spanish revenge vs. justice human rights and f...   \n\n                                                   raw true_label pred_label  \n0                     @USER @USER you are so beautiful        NOT        NOT  \n1    @USER He is not a troll he is simply dumb but ...        OFF        OFF  \n2    @USER I understand Annie she is stuck in betwe...        NOT        NOT  \n3    @USER @USER Hillary was blaming women not too ...        OFF        OFF  \n4    @USER @USER I support Jahs blessings on his hu...        OFF        NOT  \n..                                                 ...        ...        ...  \n995  @USER Sometimes I get strong vibes from people...        OFF        NOT  \n996  Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...        NOT        NOT  \n997  @USER And why report this garbage.  We don't g...        OFF        OFF  \n998                                        @USER Pussy        OFF        OFF  \n999  #Spanishrevenge vs. #justice #HumanRights and ...        NOT        NOT  \n\n[1000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>raw</th>\n      <th>true_label</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@user @user you are so beautiful</td>\n      <td>@USER @USER you are so beautiful</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@user he is not a troll he is simply dumb but ...</td>\n      <td>@USER He is not a troll he is simply dumb but ...</td>\n      <td>OFF</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@user i understand annie she is stuck in betwe...</td>\n      <td>@USER I understand Annie she is stuck in betwe...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@user @user hillary was blaming women not too ...</td>\n      <td>@USER @USER Hillary was blaming women not too ...</td>\n      <td>OFF</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@user @user i support jahs blessings on his hu...</td>\n      <td>@USER @USER I support Jahs blessings on his hu...</td>\n      <td>OFF</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>@user sometimes i get strong vibes from people...</td>\n      <td>@USER Sometimes I get strong vibes from people...</td>\n      <td>OFF</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>benidorm  check mark button   creamfields  che...</td>\n      <td>Benidorm âœ…  Creamfields âœ…  Maga âœ…   Not too sh...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>@user and why report this garbage.  we don't g...</td>\n      <td>@USER And why report this garbage.  We don't g...</td>\n      <td>OFF</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>@user pussy</td>\n      <td>@USER Pussy</td>\n      <td>OFF</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>spanish revenge vs. justice human rights and f...</td>\n      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame.from_dict({\n",
    "    'tweet': df_val['tweet'],\n",
    "    'raw': df_val['raw'],\n",
    "    'true_label': df_val['label'],\n",
    "    'pred_label': test_pipeline.predict(df_val['tweet']),\n",
    "})\n",
    "df_pred.to_csv('../predictions/val-models-output/baseline-tf-idf-linear-svm.csv', index=False)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 tweet  \\\n0    who is q wheres the server dump nike dec las f...   \n1    constitution day is revered by conservatives, ...   \n2    foxnews nra maga potus trump 2nd amendment rnc...   \n3    watching boomer getting the news that she is s...   \n4    no pasaran: unity demo to oppose the far-right...   \n..                                                 ...   \n855  despicable dems lie again about rifles. dem di...   \n856  meet the speakers  raising hands  @user will p...   \n857  3 people just unfollowed me for talking about ...   \n858  wednesday wisdom antifa calls the right fascis...   \n859         kavanaugh typical liberals , democrats url   \n\n                                                   raw true_label pred_label  \n0    #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...        OFF        NOT  \n1    #ConstitutionDay is revered by Conservatives, ...        NOT        NOT  \n2    #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...        NOT        NOT  \n3    #Watching #Boomer getting the news that she is...        NOT        NOT  \n4    #NoPasaran: Unity demo to oppose the far-right...        OFF        NOT  \n..                                                 ...        ...        ...  \n855  #DespicableDems lie again about rifles. Dem Di...        OFF        OFF  \n856  #MeetTheSpeakers ðŸ™Œ @USER will present in our e...        NOT        NOT  \n857  3 people just unfollowed me for talking about ...        OFF        OFF  \n858  #WednesdayWisdom Antifa calls the right fascis...        NOT        OFF  \n859      #Kavanaugh typical #liberals , #Democrats URL        NOT        NOT  \n\n[860 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>raw</th>\n      <th>true_label</th>\n      <th>pred_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>who is q wheres the server dump nike dec las f...</td>\n      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n      <td>OFF</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>constitution day is revered by conservatives, ...</td>\n      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>foxnews nra maga potus trump 2nd amendment rnc...</td>\n      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>watching boomer getting the news that she is s...</td>\n      <td>#Watching #Boomer getting the news that she is...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>no pasaran: unity demo to oppose the far-right...</td>\n      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n      <td>OFF</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>855</th>\n      <td>despicable dems lie again about rifles. dem di...</td>\n      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n      <td>OFF</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>meet the speakers  raising hands  @user will p...</td>\n      <td>#MeetTheSpeakers ðŸ™Œ @USER will present in our e...</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>857</th>\n      <td>3 people just unfollowed me for talking about ...</td>\n      <td>3 people just unfollowed me for talking about ...</td>\n      <td>OFF</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>wednesday wisdom antifa calls the right fascis...</td>\n      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n      <td>NOT</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>859</th>\n      <td>kavanaugh typical liberals , democrats url</td>\n      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n      <td>NOT</td>\n      <td>NOT</td>\n    </tr>\n  </tbody>\n</table>\n<p>860 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame.from_dict({\n",
    "    'tweet': df_test['tweet'],\n",
    "    'raw': df_test['raw'],\n",
    "    'true_label': df_test['label'],\n",
    "    'pred_label': test_pipeline.predict(df_test['tweet']),\n",
    "})\n",
    "df_pred.to_csv('../predictions/tst-models-output/baseline-tf-idf-linear-svm.csv', index=False)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    raw  \\\n5772  @USER He schools read a ammo box warning label...   \n5141                            @USER Because you are ðŸ’©   \n7753                             @USER Heâ€™s a dumb ass!   \n1458                 @USER Shut up man  You are useless   \n8546                                         @USER Fool   \n\n                                                  tweet label  \n5772  @user he schools read a ammo box warning label...   OFF  \n5141                @user because you are  pile of poo    OFF  \n7753                             @user heâ€™s a dumb ass!   OFF  \n1458                 @user shut up man  you are useless   OFF  \n8546                                         @user fool   OFF  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5772</th>\n      <td>@USER He schools read a ammo box warning label...</td>\n      <td>@user he schools read a ammo box warning label...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>5141</th>\n      <td>@USER Because you are ðŸ’©</td>\n      <td>@user because you are  pile of poo</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>7753</th>\n      <td>@USER Heâ€™s a dumb ass!</td>\n      <td>@user heâ€™s a dumb ass!</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>@USER Shut up man  You are useless</td>\n      <td>@user shut up man  you are useless</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>8546</th>\n      <td>@USER Fool</td>\n      <td>@user fool</td>\n      <td>OFF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = None\n",
    "df_train['len'] = df_train['tweet'].apply(len)\n",
    "df_train[df_train['len'] < 50][df_train['label'] == 'OFF'][['raw', 'tweet', 'label']].sample(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
